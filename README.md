# ğŸš€ Data Warehouse ETL Pipeline (Industry-Style Project)

## ğŸ“Œ Project Overview

This project is a **production-style Data Engineering pipeline** that builds and maintains a Data Warehouse using **Python, PostgreSQL, and automated ETL workflows**.

The system simulates how real companies (Amazon, Flipkart, Uber, etc.) continuously ingest transactional data, transform it, and generate analytics-ready datasets.

Instead of static demo data, this project includes a **data generator** that creates new orders automatically â€” allowing the warehouse to behave like a real growing system.

---

## ğŸ—ï¸ Architecture

```
Data Generator
      â†“
orders.csv (Source System)
      â†“
Staging Layer (PostgreSQL)
      â†“
Warehouse Layer (Star Schema)
      â†“
Analytics Tables
      â†“
Business Insights
```

---

## âš™ï¸ Tech Stack

* Python 3
* PostgreSQL
* Pandas
* psycopg2
* Linux / Ubuntu
* Git & GitHub
* GitHub Actions (Automation)

---

## ğŸ“‚ Project Structure

```
data_warehouse/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ orders.csv              # Source data
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.py              # Database & schema initialization
â”‚   â”œâ”€â”€ init_db.sql             # Warehouse schema
â”‚   â”œâ”€â”€ load_staging.py         # Incremental data ingestion
â”‚   â””â”€â”€ run_transform.py        # Warehouse transformations
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline.log            # Pipeline execution logs
â”‚
â”œâ”€â”€ pipeline.py                 # Main ETL Orchestrator
â”œâ”€â”€ generate_orders.py          # Data generator (NEW DATA SIMULATION)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ Pipeline Workflow

### Step 1 â€” Database Initialization

Automatically creates:

* staging schema
* warehouse schema
* analytics schema
* fact & dimension tables

---

### Step 2 â€” Data Generation

`generate_orders.py` simulates new business transactions by adding new records to:

```
data/orders.csv
```

This mimics real production systems where data keeps arriving.

---

### Step 3 â€” Incremental Loading (ETL)

Pipeline loads **only new records** using:

```
SELECT MAX(order_id)
```

This ensures:

* No duplicate loads
* Idempotent pipeline
* Production-safe ingestion

---

### Step 4 â€” Transformation

Data moves from:

```
staging â†’ warehouse â†’ analytics
```

Star schema includes:

* `sales_fact`
* `date_dim`
* `customer_dim`
* `product_dim`

---

### Step 5 â€” Analytics Layer

Example output:

```
analytics.monthly_sales
```

Provides business insights like revenue trends.

---

## â–¶ï¸ How To Run

### 1ï¸âƒ£ Setup Environment

```
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Configure Database

Create `.env` file:

```
DB_NAME=sales_warehouse
DB_USER=postgres
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432
```

---

### 3ï¸âƒ£ Run Pipeline

```
python pipeline.py
```

Expected output:

```
Database ready âœ…
Loading data into staging...
Warehouse Updated Successfully
```

---

## ğŸ¤– Automation

Pipeline can run automatically using:

* GitHub Actions (cloud execution)
* Cron Jobs (Linux scheduler)

This simulates real Data Engineering production workflows.

---

## ğŸ“Š Example Insights

Run inside PostgreSQL:

```
SELECT * FROM analytics.monthly_sales;
```

Output:

* Monthly revenue
* Aggregated business metrics
* Analytics-ready datasets

---

## â­ Key Data Engineering Concepts Implemented

* ETL Pipeline Design
* Incremental Loading
* Idempotent Processing
* Staging Layer Architecture
* Star Schema Modeling
* Pipeline Orchestration
* Logging & Monitoring
* Automated Deployment

---

## ğŸ¯ Learning Outcome

This project demonstrates how a real Data Engineer:

* Ingests growing datasets
* Builds scalable warehouses
* Automates pipelines
* Produces analytics-ready data

---

## ğŸ‘¨â€ğŸ’» Author

**Dhruv Kesarwani**

Aspiring Data Engineer building industry-level data systems.

---

## ğŸš€ Future Improvements

* Apache Airflow orchestration
* Streaming ingestion (Kafka)
* Cloud deployment (AWS/GCP)
* Dashboard integration (Power BI / Superset)

---

â­ If you found this useful, consider giving the repository a star!
