# ğŸ—ï¸ End-to-End Data Warehouse Pipeline (PostgreSQL + Python)

## ğŸ“Œ Project Overview
This project demonstrates an end-to-end Data Engineering pipeline that builds a **Data Warehouse** from raw CSV data using Python and PostgreSQL.

The pipeline automatically:
- Extracts raw data
- Loads into staging tables
- Transforms data into a Star Schema
- Updates analytics tables
- Runs incrementally (loads only new records)

---

## ğŸ§± Architecture

---

## âš™ï¸ Tech Stack

- Python 3
- PostgreSQL
- Pandas
- psycopg2
- Linux (WSL Ubuntu)
- Git & GitHub

---

## ğŸ“‚ Project Structure

---

## ğŸ”„ Pipeline Workflow

1. Read CSV data using Pandas
2. Detect last processed record
3. Load only new records (Incremental Load)
4. Insert data into staging tables
5. Transform data into:
   - Fact Table
   - Dimension Tables
6. Refresh analytics layer

---

## âœ… Features

- Incremental data loading
- Automated pipeline execution
- Logging & error handling
- Environment variable configuration (.env)
- Modular ETL design

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Clone repository

### 2ï¸âƒ£ Create virtual environment

### 3ï¸âƒ£ Install dependencies

### 4ï¸âƒ£ Setup environment variables

Create `.env` file:

### 5ï¸âƒ£ Run pipeline

---

## ğŸ“Š Example Output

- Clean warehouse tables
- Monthly sales analytics
- Automated incremental updates

---

## ğŸ¯ Learning Outcomes

This project demonstrates practical knowledge of:

- Data Warehouse Modeling
- ETL Pipeline Design
- Incremental Processing
- PostgreSQL Data Engineering
- Production-style project structure

---

## ğŸ‘¨â€ğŸ’» Author

Dhruv Kesarwani  
Aspiring Data Engineer ğŸš€
